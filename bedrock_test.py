from langchain.llms.bedrock import Bedrock
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
import boto3
import streamlit as st

# Initialize the AWS Bedrock client
bedrock_client = boto3.client(
    service_name="bedrock-runtime",
    region_name="us-east-1",
)

# Specify the AI model to use from Bedrock
model_id = "ai21.j2-mid-v1"

# Instantiate the LLM (Language Model) from Bedrock
llm = Bedrock(
    model_id=model_id,
    client=bedrock_client,
    model_kwargs={"temperature": 0.9}  # Controls response randomness
)


def my_chatbot(language, user_text):
    """
    Generates a chatbot response based on user input and selected language.

    Args:
        language (str): The language selected by the user (e.g., English, Spanish, Hindi, French).
        user_text (str): The text input/question from the user.

    Returns:
        dict: The response generated by the chatbot.
    """
    # Define the prompt template for the chatbot
    prompt = PromptTemplate(
        input_variables=["language", "user_text"],
        template="You are a chatbot. You are in {language}.\n\n{user_text}"
    )

    # Create an LLMChain that connects the prompt with the Bedrock LLM
    bedrock_chain = LLMChain(llm=llm, prompt=prompt)

    # Generate response from the chatbot
    response = bedrock_chain({'language': language, 'user_text': user_text})

    return response


# Streamlit UI for chatbot interface
st.title("Bedrock Chatbot Demo")

# Sidebar: Language selection dropdown
language = st.sidebar.selectbox("Language", ["english", "spanish", "hindi", "French"])

# Sidebar: User input text area
user_text = st.sidebar.text_area(label="What is your question?", max_chars=100)

# Process the user input and generate a response
if user_text:
    response = my_chatbot(language, user_text)
    st.write(response['text'])  # Display the chatbot's response
